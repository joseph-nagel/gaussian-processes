{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c01c32a4-aef0-4637-9764-288cd668359a",
   "metadata": {},
   "source": [
    "# GP regression\n",
    "\n",
    "An interesting application of GPs is for solving regression problems. This is usually referred to as **GP regression** (GPR) or less commonly as **Kriging**. The package `gpytorch` is used for a demonstration of GPR. We mainly follow the examples in the official documentation. In particular, a very simple regression problem based on a sine function is considered. As a first step, **hyperparameter estimation** of the GP parameters is performed. Then, the corresponding **posterior predictions** can be computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c10a5c8-2e02-4908-b874-5abb271a47fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f1e264-963b-4679-b295-8eb22266b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import gpytorch\n",
    "\n",
    "from utils.modules import ExactInferenceGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2987d0-c5ca-4489-a575-cbf5d8f7bd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e91b99c-03ff-418b-8615-95553fe4251f",
   "metadata": {},
   "source": [
    "## Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bfa440-6f83-494e-83eb-b513c192cc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    '''Calculate ground truth.'''\n",
    "    y = torch.sin(2 * torch.pi * x)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f6c438-9653-4754-837b-d3b9bb00414a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 10\n",
    "noise_std = 0.1\n",
    "\n",
    "x_train = torch.rand(num_samples)\n",
    "y_train = f(x_train) + noise_std * torch.randn_like(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0e132c-86c4-4a17-876e-7b835df0dab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = torch.linspace(0, 1, 1001)\n",
    "y_values = f(x_values)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax.plot(x_values.numpy(), y_values.numpy(), alpha=0.8, label='true function')\n",
    "ax.scatter(x_train, y_train, alpha=0.8, label='training data')\n",
    "ax.set(xlabel='x', ylabel='y')\n",
    "ax.set_xlim((0, 1))\n",
    "ax.legend()\n",
    "ax.grid(visible=True, which='both', color='lightgray', linestyle='-')\n",
    "ax.set_axisbelow(True)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896d23de-80fc-4c8b-a62f-1a2b3e18ca24",
   "metadata": {},
   "source": [
    "## Hyperparameter estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283cb775-fed7-4158-8f8b-ce1176014c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "\n",
    "model = ExactInferenceGP(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    likelihood,\n",
    "    mean='zero'\n",
    ")\n",
    "\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca9b35f-6579-4bf9-8643-6ec64ad2143b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 100\n",
    "\n",
    "model.train() # train mode for (prior) hyperparameter estimation\n",
    "likelihood.train()\n",
    "\n",
    "for idx in range(num_iterations):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    prior_mvn = model(x_train) # compute (prior) distribution in train mode\n",
    "    loss = -mll(prior_mvn, y_train) # compute negative log-likelihood loss\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (idx + 1) % 2 == 0:\n",
    "        print('Iteration {:d}, loss: {:.4f}'.format(idx + 1, loss.item()))\n",
    "\n",
    "print('\\nPrior std.: {:.4f}'.format(torch.sqrt(model.cov_module.outputscale).item()))\n",
    "print('Lengthscale: {:.4f}'.format(model.cov_module.base_kernel.lengthscale.item()))\n",
    "print('Noise std.: {:.4f}'.format(torch.sqrt(model.likelihood.noise).item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bdc013-ff42-409a-938b-821937b09e53",
   "metadata": {},
   "source": [
    "## Posterior predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499b5a7e-42ea-412c-92f1-ec8b0fe201c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval() # eval mode for posterior predictions\n",
    "likelihood.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    post_mvn = model(x_values) # compute posterior predictions in eval mode\n",
    "    pred_mvn = likelihood(post_mvn) # include likelihood data model\n",
    "\n",
    "    pred_mean = pred_mvn.mean\n",
    "    pred_std = pred_mvn.stddev\n",
    "    pred_var = pred_mvn.variance\n",
    "    pred_cov = pred_mvn.covariance_matrix\n",
    "    pred_lower, pred_upper = pred_mvn.confidence_region()\n",
    "\n",
    "    pred_samples = post_mvn.sample(sample_shape=torch.Size((100,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc32fdc4-448c-4291-a310-156a5cc865b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "true_function = ax.plot(x_values.numpy(), y_values.numpy(), alpha=0.8, zorder=3)\n",
    "training_data = ax.scatter(x_train.numpy(), y_train.numpy(), alpha=0.8, zorder=4)\n",
    "\n",
    "predictions = ax.plot(x_values.numpy(), pred_mean.numpy(), alpha=0.8, zorder=5)\n",
    "uncertainty = ax.fill_between(x_values.numpy(), pred_lower.numpy(), pred_upper.numpy(), alpha=0.2, zorder=2)\n",
    "\n",
    "ax.set_xlim((0, 1))\n",
    "ax.legend((true_function[0], training_data, predictions[0], uncertainty),\n",
    "          ('true function', 'training data', 'predictions', 'uncertainty'))\n",
    "ax.grid(visible=True, which='both', color='lightgray', linestyle='-')\n",
    "ax.set_axisbelow(True)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a29f5e-9055-49ac-86d0-46182e57a117",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax.plot(x_values.numpy(), pred_samples.T.numpy(), alpha=0.2)\n",
    "ax.set_xlim((0, 1))\n",
    "ax.grid(visible=True, which='both', color='lightgray', linestyle='-')\n",
    "ax.set_axisbelow(True)\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
